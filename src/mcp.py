#!/usr/bin/env python3
"""
Manufacturing Copilot (MCP) - Command Line Interface

Main entry point for the Manufacturing Copilot CLI. Now powered by GPT-4 for
intelligent manufacturing insights, root cause analysis, and operational
recommendations using natural language queries.

Usage:
    python src/mcp.py "Why did Freezer A use more power last night?"
    python src/mcp.py "What caused the temperature spike on Monday?"
    python src/mcp.py "Show me any anomalies in the compressor system"
"""

import argparse
import sys
import logging
from datetime import datetime, timedelta
from typing import Optional

# Add the project root to the Python path for imports
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.llm_interpreter import llm_interpret_query
from src.interpreter import interpret_query as legacy_interpret_query
from src.glossary import TagGlossary
from src.tools import load_data, summarize_metric, quality_summary
from src.tools.data_loader import get_data_time_range

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ManufacturingCopilot:
    """
    Main Manufacturing Copilot engine powered by GPT-4 for intelligent
    manufacturing insights and operational recommendations.
    
    Now features LLM-powered analysis that provides expert-level insights
    like a senior process engineer would.
    """
    
    def __init__(self, use_llm: bool = True):
        """Initialize the MCP with LLM or legacy interpreter."""
        print("üè≠ Manufacturing Copilot - Initializing...")
        
        self.use_llm = use_llm
        
        try:
            if use_llm:
                print("   üß† Using GPT-4 powered intelligent analysis...")
                # Check OpenAI API key
                if not os.getenv('OPENAI_API_KEY'):
                    print("   ‚ö†Ô∏è  Warning: OPENAI_API_KEY not found in environment")
                    print("   Falling back to legacy interpreter...")
                    self.use_llm = False
                else:
                    print("   ‚úÖ GPT-4 ready for expert-level manufacturing insights!")
            
            if not self.use_llm:
                # Initialize tag glossary for semantic search (legacy mode)
                print("   üìö Loading tag glossary with semantic search...")
                self.glossary = TagGlossary()
                print(f"   ‚úÖ Loaded {len(self.glossary.list_all_tags())} tags for analysis")
            
            print("   Ready for natural language queries!\n")
            
        except Exception as e:
            print(f"   ‚ùå Initialization failed: {e}")
            print("   Make sure OPENAI_API_KEY is set in your .env file")
            sys.exit(1)
    
    def process_query(self, query: str, time_window_hours: int = 24) -> None:
        """
        Process a natural language query and provide intelligent insights.
        
        Args:
            query: Natural language question about manufacturing operations
            time_window_hours: How many hours of recent data to analyze (legacy mode only)
        """
        print(f"üîç Query: '{query}'")
        print("=" * 60)
        
        if self.use_llm:
            # Use the LLM-powered interpreter for intelligent analysis
            try:
                result = llm_interpret_query(query)
                print(result)
                print()
                print("üéØ **LLM-Powered Analysis Complete!**")
                print("   ‚Ä¢ Expert-level insights generated by GPT-4")
                print("   ‚Ä¢ Manufacturing domain expertise applied")
                print("   ‚Ä¢ Actionable recommendations provided")
            except Exception as e:
                logger.error(f"Error processing query with LLM: {e}")
                print(f"   ‚ùå LLM Analysis Error: {e}")
                print("   üí° Try checking your OpenAI API key or use --legacy mode")
        else:
            # Use the legacy detailed processing mode
            self._process_query_legacy(query, time_window_hours)
    
    def _process_query_legacy(self, query: str, time_window_hours: int = 24) -> None:
        """Legacy detailed query processing method."""
        try:
            result = legacy_interpret_query(query)
            print(result)
            print()
            print("‚úÖ Legacy analysis complete! Consider using LLM mode for deeper insights:")
            print("   ‚Ä¢ Run without --legacy flag for GPT-4 powered analysis")
            print("   ‚Ä¢ Get expert-level manufacturing insights")
            print("   ‚Ä¢ Receive actionable operational recommendations")
            
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            print(f"   ‚ùå Error: {e}")


def main():
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(
        description="Manufacturing Copilot - LLM-Powered Manufacturing Data Analysis",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # LLM-Powered Analysis (Default - Recommended!)
  python src/mcp.py "Why did Freezer A use more power last night?"
  python src/mcp.py "What caused the temperature spike yesterday?"
  python src/mcp.py "Show me any anomalies in the compressor system"
  python src/mcp.py "Give me a complete analysis of freezer performance"
  
  # Legacy Mode (Deterministic Analysis)
  python src/mcp.py "Show me freezer temperatures" --legacy
  python src/mcp.py "Door activity patterns" --legacy --hours 48
        """
    )
    
    parser.add_argument(
        "query",
        help="Natural language question about manufacturing operations"
    )
    
    parser.add_argument(
        "--hours",
        type=int,
        default=24,
        help="Number of hours of data to analyze (legacy mode only, default: 24)"
    )
    
    parser.add_argument(
        "--legacy",
        action="store_true",
        help="Use legacy deterministic analysis instead of LLM-powered insights"
    )
    
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose logging"
    )
    
    args = parser.parse_args()
    
    # Set logging level
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Initialize and run MCP
    try:
        mcp = ManufacturingCopilot(use_llm=not args.legacy)
        mcp.process_query(args.query, args.hours)
        
    except KeyboardInterrupt:
        print("\nüõë Operation cancelled by user")
        sys.exit(0)
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        print(f"‚ùå Unexpected error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 